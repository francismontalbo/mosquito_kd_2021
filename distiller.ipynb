{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DEPENDENCIES\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import applications, Model, layers\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.losses import KLDivergence, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.layers import DepthwiseConv2D, Activation, BatchNormalization, Layer\n",
    "\n",
    "model_architecture = \"proposed_model_kd\"\n",
    "\n",
    "#PREVENT ERROR UNCESSARY MESSAGES\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4879d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset path\n",
    "data_path = \"dataset\"\n",
    "\n",
    "#Student and teacher name\n",
    "student_name = 'proposed_model'\n",
    "teacher_name = 'EfficientNetB7'\n",
    "\n",
    "#Model, Figures and Data  paths\n",
    "distilled_student_model_path = 'models/Distilled_Student_Models/'\n",
    "teacher_model_path = 'models/teacher_model/'\n",
    "student_model_path = 'models/proposed_model/'\n",
    "kd_model_path = 'models/kd_model/'\n",
    "\n",
    "model_kind = 'KD_model'\n",
    "\n",
    "model_kd = model_kind\n",
    "\n",
    "model_path = \"models/\" + model_kind + '/'\n",
    "\n",
    "#Custom Functions\n",
    "\n",
    "#Load Model Function\n",
    "def load_m_teacher(directory):\n",
    "    with open(directory + '/' + teacher_name + '.json', \"r\") as json_file:\n",
    "        teacher_model = json_file.read()\n",
    "        teacher_model = model_from_json(teacher_model)\n",
    "        teacher_model.load_weights(directory + '/' + teacher_name + '.h5')\n",
    "        return teacher_model\n",
    "\n",
    "def load_m_student(directory):\n",
    "    with open(directory + '/' + student_name + '.json', \"r\") as json_file:\n",
    "        student_model = json_file.read()\n",
    "        student_model = model_from_json(student_model)\n",
    "        student_model.load_weights(directory + '/' + student_name + '.h5')\n",
    "        return student_model\n",
    "\n",
    "#Load History\n",
    "def load_h(file):\n",
    "    with open('models/' + model_kind + '/' + model_architecture + '/' + model_architecture + '.history', 'rb') as file_pi:\n",
    "        his = pickle.load(file_pi)\n",
    "    return his\n",
    "\n",
    "#Save Model Function\n",
    "def save_m(directory, model):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    model.save(directory + '/' + model_architecture + '.h5')\n",
    "    print(\"model saved\")\n",
    "\n",
    "#Save History Function\n",
    "def save_h(directory, his):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(directory + '/' + model_architecture + '.history', 'wb') as file_pi:\n",
    "        pickle.dump(his, file_pi)\n",
    "    print(\"history saved\")\n",
    "\n",
    "#Save Figure Function\n",
    "def save_fig(directory, fig_name):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    plt.savefig(directory + '/' + fig_name + '.tiff', bbox_inches='tight', dpi=600, format='tiff')\n",
    "    \n",
    "#Get data from generator function\n",
    "def get_data(generator, nb_samples):  \n",
    "    from tqdm.notebook import tqdm\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in tqdm(range(math.ceil(nb_samples/batch_size))):\n",
    "        x.extend(generator[i][0])\n",
    "        y.extend(generator[i][1])\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "#Create generator from data function\n",
    "def get_generator(x, y, preprocessing_function=None, rescale=None, shuffle=True,):\n",
    "    datagen = ImageDataGenerator(rescale=rescale, preprocessing_function=preprocessing_function)\n",
    "    datagen = datagen.flow(x, y, batch_size=batch_size, shuffle=shuffle)\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44139912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE DATA\n",
    "\n",
    "class_names = ['0_Non_vectors', \n",
    "                '1_Aedes_albopictus', \n",
    "                '2_Aedes_vexans', \n",
    "                '3_Anopheles_sinensis', \n",
    "                '4_Culex_pipiens', \n",
    "                '5_Culex_tritaeniorhynchus']\n",
    "\n",
    "cm_target_names = ['0', '1', '2', '3', '4', '5']\n",
    "\n",
    "print(\"Class names:\", class_names)\n",
    "print()\n",
    "\n",
    "train_data_dir = data_path + \"/train/\"\n",
    "validation_data_dir = data_path + \"/validation/\"\n",
    "test_data_dir = data_path + \"/test/\"\n",
    "\n",
    "#Image specifications and handling\n",
    "batch_size = 16\n",
    "img_rows, img_cols = 224, 224\n",
    "input_shape = (img_rows,img_cols,3)\n",
    "\n",
    "model_input = Input(shape=input_shape)\n",
    "print(\"Data folders found!\")\n",
    "print()\n",
    "print(\"The Input size is set to \", model_input) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select type of model\n",
    "fig_path = 'figures/' + model_kind + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155982da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA GENERATORS\n",
    "epochs = 30\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "         \n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_rows,img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=42,\n",
    "        classes=class_names)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows,img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        classes=class_names)\n",
    "\n",
    "#CHECK  THE NUMBER OF SAMPLES\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "\n",
    "if nb_train_samples == 0:\n",
    "    print(\"NO DATA TRAIN FOUND! Please check your train data path and folders!\")\n",
    "else:\n",
    "    print(nb_train_samples, \"Train samples found!\")\n",
    "    \n",
    "if nb_validation_samples == 0:\n",
    "    print(\"NO DATA VALIDATION FOUND! Please check your validation data path and folders!\")\n",
    "    print(\"Check the data folders first!\")\n",
    "else:\n",
    "    print(nb_validation_samples, \"Validation samples found!\")\n",
    "\n",
    "#check the class indices\n",
    "train_generator.class_indices\n",
    "validation_generator.class_indices\n",
    "\n",
    "#true labels\n",
    "Y_test=validation_generator.classes\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "print('Model set to train', num_classes, 'classes')\n",
    "\n",
    "if nb_train_samples and nb_validation_samples > 0:\n",
    "    print(\"Generators are set!\")\n",
    "    print(\"Check if dataset is complete and has no problems before proceeding.\")\n",
    "\n",
    "if num_classes == 2:\n",
    "    loss='binary_crossentropy'\n",
    "    activation_classifier = 'sigmoid'\n",
    "    print(\"loss function is set to:\", loss)\n",
    "    print(\"activation classifier is set to:\", activation_classifier)\n",
    "else:\n",
    "    loss='categorical_crossentropy'\n",
    "    activation_classifier = 'softmax'\n",
    "    print(\"loss function is set to:\", loss)\n",
    "    print(\"activation classifier is set to:\", activation_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad008b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDistiller(Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(KDistiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha,\n",
    "        temperature,\n",
    "    ):\n",
    "        super(KDistiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "\n",
    "        # Forward pass of teacher\n",
    "        teacher_preds = self.teacher(x, training=False) #Soft labels\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_preds = self.student(x, training=True) #Soft predictions\n",
    "\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_preds) #Categorical Cross Entropy Loss\n",
    "            distillation_loss = self.distillation_loss_fn( #Total loss\n",
    "                tf.nn.softmax(teacher_preds / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_preds / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics \n",
    "        self.compiled_metrics.update_state(y, student_preds)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss, 'combined_loss':loss}\n",
    "        )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_preds = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        student_loss = self.student_loss_fn(y, y_preds)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_preds)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        return self.student(inputs, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c236a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load teacher model\n",
    "teacher_model = tf.keras.models.load_model(teacher_model_path + teacher_name + '/' + teacher_name + '.h5')\n",
    "\n",
    "print(\"Teacher model\", teacher_model.name, \"successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check teacher\n",
    "teacher_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19657ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare validation generator for sanity check\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows,img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        classes=class_names)\n",
    "\n",
    "#Sanity check the teacher model first\n",
    "teacher_model.evaluate(validation_generator, \n",
    "                    batch_size=batch_size, \n",
    "                    steps=nb_validation_samples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the student model\n",
    "student_model = tf.keras.models.load_model(student_model_path + student_name + '/' + student_name + '.h5')\n",
    "\n",
    "print(\"Student model\", student_model.name, \"successfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the student model\n",
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get training data in x, y format for distillation\n",
    "print(\"Loading Training Data\")\n",
    "x_train, y_train = get_data(train_generator, nb_train_samples)\n",
    "\n",
    "print(\"Loading Validation Data\")\n",
    "x_val, y_val = get_data(validation_generator, nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set training constants\n",
    "epochs = 30\n",
    "optimizer = Adam\n",
    "learning_rate = 0.001\n",
    "alpha=1.0\n",
    "temperature = 2\n",
    "print(\"Batch size is set to:\", batch_size)\n",
    "print(\"Epoch is set to:\", epochs)\n",
    "print(\"Loss is set to:\", loss)\n",
    "print(\"Learning rate is set to:\", learning_rate)\n",
    "print(\"Optimizer is set to:\", optimizer.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distill teacher to student\n",
    "\n",
    "#Create Knowledge distiller\n",
    "distiller = KDistiller(student=student_model, teacher=teacher_model)\n",
    "\n",
    "#Compile Knowledge distiller\n",
    "distiller.compile(\n",
    "    optimizer = optimizer(learning_rate=learning_rate),\n",
    "    metrics=[CategoricalAccuracy()],\n",
    "    student_loss_fn=CategoricalCrossentropy(),\n",
    "    distillation_loss_fn= KLDivergence(),\n",
    "    alpha=alpha,\n",
    "    temperature=temperature,\n",
    "    )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2,\n",
    "                              verbose=1, mode='min', min_lr=0.000001)\n",
    "\n",
    "callbacks = [reduce_lr]\n",
    "\n",
    "#Get train and val generator\n",
    "train_generator = get_generator(x_train, y_train, preprocessing_function=preprocess_input)\n",
    "validation_generator = get_generator(x_val, y_val, preprocessing_function=preprocess_input)\n",
    "\n",
    "#Training\n",
    "distiller_history = distiller.fit(train_generator,\n",
    "                                  validation_data = validation_generator,\n",
    "                                  steps_per_epoch = nb_train_samples // batch_size,\n",
    "                                  validation_steps = nb_validation_samples// batch_size,\n",
    "                                  callbacks=callbacks,\n",
    "                                  epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ff6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the distillation of soften knowledge to the proposed student\n",
    "KD_student = distiller.student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cea036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the KD student for a sanity check\n",
    "KD_student.compile(\n",
    "          optimizer = optimizer(learning_rate=learning_rate),\n",
    "          loss = CategoricalCrossentropy(from_logits=True),\n",
    "          metrics = [CategoricalAccuracy()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c552d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the validation generator for a sanity check\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_rows,img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        classes=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052302df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the KD student\n",
    "KD_student.evaluate(validation_generator, \n",
    "                    batch_size=batch_size, \n",
    "                    steps=nb_validation_samples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "save_m(kd_model_path + model_architecture, KD_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e08c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "model = load_model(kd_model_path + model_architecture + '/' + model_architecture + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9baa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the history\n",
    "save_h(kd_model_path + model_architecture, distiller_history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the history\n",
    "history = load_h(model_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the KD model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d6b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform another sanity check to make sure that the results did not change\n",
    "model.evaluate(validation_generator, \n",
    "                    batch_size=batch_size, \n",
    "                    steps=nb_validation_samples / batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
